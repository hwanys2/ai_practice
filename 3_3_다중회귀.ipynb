{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-3 다중회귀.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOE4/ZqNPYf0qFryyCSuAcz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwanys2/ai_practice/blob/main/3_3_%EB%8B%A4%EC%A4%91%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다중 회귀 및 규제 \n",
        "여러 개의 특성을 사용한 선형 회귀를 **다중 회귀**라고 합니다.\n",
        "여러 개읱 특성을 그대로 사용하는 거이 아니라 각 특성의 곱을 이용하여 새로운 특성들을 만들어 사용합니다. 이런 작업을 **특성공학**이라고 부릅니다.  \n",
        "<br>\n",
        "농어 길이의 세가지 특성 정보를 가지고 오겠습니다.  \n",
        "pandas를 이용하여 dataframe으로 만들고, 이를 넘파이 배여롤 바꾸어 출력해보겠습니다.\n"
      ],
      "metadata": {
        "id": "PDoIRbyUr_P8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgyR1JF_qBH7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # pd는 관례적으로 사용하는 판다스의 별칭입니다\n",
        "df = pd.read_csv('https://bit.ly/perch_csv_data')\n",
        "perch_full = df.to_numpy()\n",
        "print(perch_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 자료에 해당하는 무게 정보를 입력하겠습니다. 즉, 정답을 주는 일입니다."
      ],
      "metadata": {
        "id": "GDCdSyCNtD5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "perch_weight = np.array(\n",
        " [ 5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, \n",
        " 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, \n",
        " 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, \n",
        " 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, \n",
        " 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, \n",
        " 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, \n",
        " 1000.0, 1000.0]\n",
        " )"
      ],
      "metadata": {
        "id": "rrPMoVLYqzD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 훈련데이터와 테스트데이터로 나누겠습니다. sklarn의 train_test_split 를 이용합니다."
      ],
      "metadata": {
        "id": "rEaIC_NGtWDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_input, test_input, train_target, test_target = train_test_split(perch_full, perch_weight, random_state=42)"
      ],
      "metadata": {
        "id": "W9zPso68q9dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "계속 진행하기에 앞서 특성공학 작업을 진행해주는 라이브러리에 대해 알아보겠습니다.  \n",
        "poly = PolynomialFeatures() 로 객체를 생성합니다. 이때 기본적으로 degree=2 입니다.  \n",
        "이경우 아래와 같은 결과를 얻을 수 있습니다.\n",
        "x, y인 자료를 2차원의 특성공학을 진행하면  \n",
        "1, $x$, $y$, $x^2$, $xy$, $y^2$  \n",
        "의 값을 얻게 되어 다음과 같이 출력됩니다.  \n",
        "차원을 늘리면 최고차항이 커지며 더 많은 특성들을 생성하게 됩니다.\n",
        "각 값의 의미를 알기 위해서는 다음과 같은 명령어로 가능합니다.\n",
        "\n",
        "\n",
        "```\n",
        "poly.get_feature_names()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "aTLLJlQotghz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures()\n",
        "poly.fit([[2, 3]])\n",
        "print(poly.transform([[2, 3]]))\n",
        "print(poly.get_feature_names())"
      ],
      "metadata": {
        "id": "aJmQ6tUgrH4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "예를 들어 차원을 5라고하면 다음과 같이 특성들을 만들어 내게 됩니다.  \n",
        "또한 include_bias=False 를 추가하면 기본 1은 제거해 줍니다.  \n"
      ],
      "metadata": {
        "id": "s5S5EhjgvuvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(degree=5, include_bias=False)\n",
        "poly.fit(train_input)\n",
        "poly.fit([[2, 3]])\n",
        "print(poly.transform([[2, 3]]))\n",
        "print(poly.get_feature_names())"
      ],
      "metadata": {
        "id": "n-U2d31urX8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 특성 변환 하기\n",
        "이제 훈련데이터와 테스트 데이터를 직접 넣어 2차원 특성들을 만들고 선형회귀 모델을 만들어보겠습니다."
      ],
      "metadata": {
        "id": "hnrtAqfbxKaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(include_bias=False)\n",
        "poly.fit(train_input)\n",
        "train_poly = poly.transform(train_input)    # 훈련 데이터 변환\n",
        "test_poly = poly.transform(test_input)      # 테스트 데이터 변환\n",
        "print(train_poly.shape)"
      ],
      "metadata": {
        "id": "wpptBc7trkW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다중회귀 모델 훈련시키기\n",
        "위의 결과를 보면 농어가 가지는 3가지 특성의 곱을 통해 9가지 특성으로 늘인건을 확인할 수 있습니다.  \n",
        "이 자료를 skearn의 선형회귀 모델을 통해 훈련시키겠습니다."
      ],
      "metadata": {
        "id": "nMe-QYNIx2i6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()\n",
        "lr.fit(train_poly, train_target)\n",
        "print('훈련데이터에 대한 정확도 점수는:',lr.score(train_poly, train_target))\n",
        "print('테스트데이터에 대한 정확도 점수는:',lr.score(test_poly, test_target))"
      ],
      "metadata": {
        "id": "1AQxZMJux_sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "만족할 만한 점수가 나오는 것 같습니다.  \n",
        "만약 특성을 더 많이 추가하면 어떻게 될까요?  \n",
        "5제곱까지 넣어서 동일하게 진행해보겠습니다."
      ],
      "metadata": {
        "id": "xSZxnQuGy0-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(degree=5, include_bias=False)\n",
        "poly.fit(train_input)\n",
        "train_poly = poly.transform(train_input)    # 훈련 데이터 변환\n",
        "test_poly = poly.transform(test_input)      # 테스트 데이터 변환\n",
        "lr = LinearRegression()\n",
        "lr.fit(train_poly, train_target)\n",
        "print('훈련데이터에 대한 정확도 점수는:',lr.score(train_poly, train_target))\n",
        "print('테스트데이터에 대한 정확도 점수는:',lr.score(test_poly, test_target))"
      ],
      "metadata": {
        "id": "vcHwcxhPzI0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 데이터는 완벽한 점수가 나오지만  \n",
        "테스트 데이터는 음수가 나오는 것을 확인할 수 있습니다.  \n",
        "현재 42개의 훈련데이터를 예측하기위해 데이터보다 더 많은 55개의 특성을 사용하게 되어 거의 100% 예측이 가능하게 된것입니다.  \n",
        "반면에 훈련세트에 과대적합되어 테스트 세트에서는 형편없는 점수를 만든 것입니다.  \n",
        "이러한 문제를 해결하기 위해 특성을 줄이거나 **규제**가 필요합니다.\n",
        "## 규제\n",
        "과대적합을 막기 위해 선형 회귀 모델의 경우 특성에 곱해지는 계수의 크기를 작게 만드는 일입니다.  \n",
        "이때 릿지와 라쏘 방식을 사용할 수 있다.  \n",
        "라쏘는 가중치들이 0이 되지만, 릿지의 가중치들은 0에 가까워질 뿐 0이 되지는 않습니다. 특성이 많은데 그중 일부분만 중요하다면 라쏘가, 특성의 중요도가 전체적으로 비슷하다면 릿지가 좀 더 괜찮은 모델을 찾아줄 것입니다.   \n",
        "계수를 변화시켜주는 것이기 때문에 계수 값의 크기가 서로 많이 다르면 공정하게 제어되지 않을 수 있습니다.  \n",
        "따라서 표준점수로 먼저 바꾸어 주어야 합니다.  \n",
        "사이킷런에서 제공하는 라이브러리를 사용하여 변환하겠습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "_6DcaKVYzYWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "ss.fit(train_poly)\n",
        "train_scaled = ss.transform(train_poly)\n",
        "test_scaled = ss.transform(test_poly)"
      ],
      "metadata": {
        "id": "eLz4lDaQ2txs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 릿지 회귀\n",
        "릿지 회귀를 이용하여 5차원으로 특성을 만든 데이터를 회귀분석한 모델의 정확도를 구해보겠습니다."
      ],
      "metadata": {
        "id": "T1741e1m2MlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "ridge = Ridge()\n",
        "ridge.fit(train_scaled, train_target)\n",
        "print('훈련데이터에 대한 정확도 점수는:',ridge.score(train_scaled, train_target))\n",
        "print('테스트데이터에 대한 정확도 점수는:',ridge.score(test_scaled, test_target))"
      ],
      "metadata": {
        "id": "QLfldm6lzzzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트데이터에 대한 정학도가 돌아온 것을 확인할 있습니다.  \n",
        "릿지 회귀에는 하이퍼파리미터 값이 존재합니다. alpha 라는 변수에 값을 입력하여 규제의 양을 정할 수 있습니다.  \n",
        "alpha값이 크면 규제를 강하게 하여 조금 더 과소적합되도록 유도합니다. 반대로 작으면 과대적합가능성이 커집니다.  \n",
        "이를 확인하기 위해 alpha값에 대한 $R^2$값의 그래프를 그려보겠습니다."
      ],
      "metadata": {
        "id": "4maCWIIn3WBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_score = []\n",
        "test_score = []\n",
        "alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "for alpha in alpha_list:\n",
        "    # 릿지 모델을 만듭니다\n",
        "    ridge = Ridge(alpha=alpha)\n",
        "    # 릿지 모델을 훈련합니다\n",
        "    ridge.fit(train_scaled, train_target)\n",
        "    # 훈련 점수와 테스트 점수를 저장합니다\n",
        "    train_score.append(ridge.score(train_scaled, train_target))\n",
        "    test_score.append(ridge.score(test_scaled, test_target))\n",
        "# 그래프로 표현. alpha 값이 10배씩 커지므로 로그 사용\n",
        "plt.plot(np.log10(alpha_list), train_score)\n",
        "plt.plot(np.log10(alpha_list), test_score)\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('R^2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ogoJq2DN3JAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 그래프를 보면 테스트셋에 대한 점수가 -1, 즉 $1/10$일 때 가장 큰 것을 확인할 수 있어 alpha값을 0.1로 주는 것이 적합해보입니다. 이를 바탕으로 훈련시키면\n"
      ],
      "metadata": {
        "id": "XyPEpbpC4hQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge(alpha=0.1)\n",
        "ridge.fit(train_scaled, train_target)\n",
        "print('훈련데이터에 대한 정확도 점수는:',ridge.score(train_scaled, train_target))\n",
        "print('테스트데이터에 대한 정확도 점수는:',ridge.score(test_scaled, test_target))"
      ],
      "metadata": {
        "id": "kBlTJxcV4xpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "alpha를 지정하기 전보다 훈련 및 테스트 데이터 점수가 모두 좋아진 것을 확인할 수 있습니다.\n",
        "### 라쏘회귀\n",
        "당ㅁ으로 라쏘회귀도 진행해보겠습니다. 방법은 유사합니다."
      ],
      "metadata": {
        "id": "VrK1hctV458E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso()\n",
        "lasso.fit(train_scaled, train_target)\n",
        "print('훈련데이터에 대한 정확도 점수는:',lasso.score(train_scaled, train_target))\n",
        "print('테스트데이터에 대한 정확도 점수는:',lasso.score(test_scaled, test_target))"
      ],
      "metadata": {
        "id": "EH_3PCuf43ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "마찬가지로 alpha값을 찾아보도록 하겠습니다."
      ],
      "metadata": {
        "id": "NqlvJlU55YKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = []\n",
        "test_score = []\n",
        "alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "for alpha in alpha_list:\n",
        "    # 라쏘 모델을 만듭니다\n",
        "    lasso = Lasso(alpha=alpha, max_iter=10000)\n",
        "    # 라쏘 모델을 훈련합니다\n",
        "    lasso.fit(train_scaled, train_target)\n",
        "    # 훈련 점수와 테스트 점수를 저장합니다\n",
        "    train_score.append(lasso.score(train_scaled, train_target))\n",
        "    test_score.append(lasso.score(test_scaled, test_target))\n",
        "\n",
        "plt.plot(np.log10(alpha_list), train_score)\n",
        "plt.plot(np.log10(alpha_list), test_score)\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('R^2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zvr5i_VK5XJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 경우 1인 경우 즉 alpha 가 10인 경우가 가장 높습니다. alpha를 10으로 설정하고 진행해보겠습니다."
      ],
      "metadata": {
        "id": "663A5iw45WvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso(alpha=10)\n",
        "lasso.fit(train_scaled, train_target)\n",
        "print('훈련데이터에 대한 정확도 점수는:',lasso.score(train_scaled, train_target))\n",
        "print('테스트데이터에 대한 정확도 점수는:',lasso.score(test_scaled, test_target))"
      ],
      "metadata": {
        "id": "mRDlAvQv5yV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "라쏘 모델의 경우 계수 값을 아예 0으로 만들어 몇몇 특성들을 사용하지 않게 만든다고 하였습니다. \n",
        "이를 확인하기 위해 계수 값을 살펴보겠습니다.  \n",
        "계수 값은 coef_ 속성에 저장되어 있습니다.  \n",
        "이중 0인 것을 헤아려 보겠습니다.\n"
      ],
      "metadata": {
        "id": "mWwBnN--5_Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(lasso.coef_ == 0))"
      ],
      "metadata": {
        "id": "rro11bgY6O1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "55개의 특성중 40개의 계수가 0이니 15개의 특성만을 이용하여 모델을 구현한 것을 확인할 수 있습니다.  \n",
        "따라서 중요한 특성이 무엇인지 확인할 때 라쏘 모델을 확인할 수도 있겠습니다."
      ],
      "metadata": {
        "id": "rI07lehj6R7m"
      }
    }
  ]
}